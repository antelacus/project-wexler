# 📊 模型评估与结果展示

本页总结模型的训练效果、评估指标、结果可视化，以及项目阶段性的结论与后续优化方向。

---

## 🎯 评估指标设计与选型

在推荐系统中，传统的分类准确率指标（如 accuracy）不适用于排序任务。因此，我们选用了更能反映实际推荐效果的**排序评估指标**：

### ✅ Precision@K

- **含义**：用户收到的前 K 个推荐中，有多少是他们真正喜欢/点击/购买的。
- **应用场景**：度量推荐系统的“命中率”。

### ✅ Recall@K

- **含义**：用户所有可能喜欢的物品中，有多少在推荐结果的前 K 个中出现。
- **应用场景**：衡量推荐的“覆盖面”。

### ✅ NDCG（可选）

- **含义**：考虑了推荐项的排序位置，对排名越靠前的推荐给予更高权重。
- **优势**：反映排序质量而不仅仅是是否命中。

我们在本项目中主要使用 **Precision@K 和 Recall@K** 进行模型评估，采用标准划分的训练集和验证集进行测试。

---

## 📈 模型结果摘要

以下为基于 Retailrocket 数据集训练出的 LightFM 模型在不同指标下的表现（示例数值）：

| 指标         | 值         |
|--------------|------------|
| Precision@5  | 0.146      |
| Recall@10    | 0.221      |
| 训练耗时     | 22 秒      |

模型在小规模训练集下已展现出较好的精度，在 Recall 方面也具有可接受的表现，说明该算法能较好捕捉用户的潜在偏好。

---

## 📊 可视化分析

在 Notebook 中，我们利用如下方式进一步验证模型合理性：

- **用户嵌入空间可视化**：通过 PCA 或 t-SNE 降维显示相似用户聚类情况
- **推荐商品分析**：统计推荐集中度、覆盖度
- **训练损失曲线**：观察是否过拟合或欠拟合

👉 详情见：[Project_Wexler_Code.ipynb](https://github.com/antelacus/project-wexler/blob/main/Project_Wexler_Code.ipynb)

---

## ✅ 项目总结与优化建议

### 当前成果

- 构建并训练了一个完整的推荐系统原型
- 使用真实电商数据进行模型验证
- 模型在排序精度方面达成预期，支持基本的冷启动推荐能力

### 后续优化方向

- 🔧 **特征丰富性**：增加时间、用户设备等上下文特征
- 🧠 **参数调优**：引入网格搜索或 Bayesian Optimization 进一步优化 WARP 参数
- 🌐 **系统部署**：将模型封装为在线 API 或开发简单前端页面进行展示
- 🧪 **A/B 测试设计**：模拟用户反馈机制，引入在线评估能力

---

本项目展示了如何从数据出发，构建可落地的推荐系统原型，并验证其性能，具备良好的可扩展性和商业应用潜力。
